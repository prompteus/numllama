{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a542467",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:6\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c875c",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b08b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import collections\n",
    "\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import tqdm.auto\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5bca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_encode(\n",
    "    x: Tensor,\n",
    "    embedding_dim: int,\n",
    "    min_value: int,\n",
    "    max_value: int,\n",
    "    use_l2_norm: bool = False,\n",
    "    norm_const: float | None = None,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Encodes a tensor of numbers into a sinusoidal representation, inspired by how absolute positional\n",
    "    encoding works in transformers.\n",
    "\n",
    "    The encoding is an evaluation of a sine and cosine function at different frequencies, where the\n",
    "    frequency is determined by the embedding dimension and the allowed range of the input values.\n",
    "\n",
    "    >>> sinusoidal_encode(\n",
    "    ...     torch.tensor([-5, 2, 1, 0]),\n",
    "    ...     embedding_dim=6,\n",
    "    ...     min_value=-5,\n",
    "    ...     max_value=5,\n",
    "    ... )\n",
    "    tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
    "            [ 0.6570,  0.7539, -0.1073, -0.9942,  0.9980,  0.0627],\n",
    "            [-0.2794,  0.9602,  0.3491, -0.9371,  0.9616,  0.2746],\n",
    "            [-0.9589,  0.2837,  0.7317, -0.6816,  0.8806,  0.4738]])\n",
    "    \"\"\"\n",
    "\n",
    "    if embedding_dim % 2 != 0 and not use_l2_norm:\n",
    "        raise ValueError(\"Embedding dimension must be even\")\n",
    "\n",
    "    if use_l2_norm:\n",
    "        if embedding_dim % 2 == 0:\n",
    "            reserved_dim = 2\n",
    "        else:\n",
    "            reserved_dim = 1\n",
    "        embedding_dim -= reserved_dim\n",
    "    else:\n",
    "        reserved_dim = 0  # will not be used\n",
    "\n",
    "    domain = max_value - min_value\n",
    "    y_shape = x.shape + (embedding_dim,)\n",
    "    y = torch.zeros(y_shape, device=x.device)\n",
    "    even_indices = torch.arange(0, embedding_dim, 2)\n",
    "    log_term = torch.log(torch.tensor(domain)) / embedding_dim\n",
    "    div_term = torch.exp(even_indices * -log_term)\n",
    "    x = x - min_value\n",
    "    values = x.unsqueeze(-1).float() * div_term\n",
    "    y[..., 0::2] = torch.sin(values)\n",
    "    y[..., 1::2] = torch.cos(values)\n",
    "\n",
    "    if use_l2_norm:\n",
    "        y = torch.cat([y, torch.ones_like(y[..., :reserved_dim])], dim=-1)\n",
    "        y /= y.norm(dim=-1, keepdim=True, p=2)\n",
    "\n",
    "    if norm_const is not None:\n",
    "        y *= norm_const\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff97ee3",
   "metadata": {},
   "source": [
    "### Prepare model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8723d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModel.from_pretrained(\"meta-llama/Llama-3.2-1B\").eval()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b394470",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = torch.arange(0, 1000)\n",
    "mask = torch.rand(len(all_values), generator=torch.Generator().manual_seed(0))\n",
    "train_mask = mask < 0.9\n",
    "valid_mask = ~train_mask & (mask < 0.95)\n",
    "test_mask = ~train_mask & ~valid_mask\n",
    "\n",
    "train_values = all_values[train_mask]\n",
    "valid_values = all_values[valid_mask]\n",
    "test_values = all_values[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41d1f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3500789', '3000001')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_str_input(nums: list) -> str:\n",
    "    return str(nums[0]) + \"\".join(str(n).zfill(3) for n in nums[1:])\n",
    "\n",
    "make_str_input([3, 500, 789]), make_str_input([3, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5ad909",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(0)\n",
    "\n",
    "train_size = 200_000\n",
    "\n",
    "x_values_train = [(i, j) for i, j in zip(\n",
    "    rng.choices(train_values.tolist(), k=train_size),\n",
    "    rng.choices(train_values.tolist(), k=train_size)\n",
    ")]\n",
    "x_values_valid = list(itertools.product(valid_values.tolist(), repeat=2))\n",
    "x_values_test = list(itertools.product(test_values.tolist(), repeat=2))\n",
    "\n",
    "x_inputs_valid = tokenizer(list(map(make_str_input, x_values_valid)), return_tensors=\"pt\")\n",
    "x_inputs_valid = tokenizer(list(map(make_str_input, x_values_test)), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dd2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(model, str_inputs: list[str]) -> collections.defaultdict[int, Tensor]:\n",
    "    model.eval()\n",
    "    hidden_states = collections.defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for batch_str in itertools.batched(tqdm.auto.tqdm(str_inputs), n=128):\n",
    "            batch_inputs = tokenizer(batch_str, return_tensors=\"pt\")\n",
    "            hidden_reprs = model(**batch_inputs.to(model.device), output_hidden_states=True).hidden_states\n",
    "            for layer_idx, hidden_state in enumerate(hidden_reprs):\n",
    "                hidden_states[layer_idx].extend(hidden_state[:, -1, :].detach().cpu())\n",
    "    return {k: torch.stack(v) for k, v in hidden_states.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da87aca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143278ea9ab34628b6b557e6708fb218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed796b3e32d64240b01f5d3c63406e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7db7dd6f5cf4435a1b57547b261c720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_hidden_states = get_hidden_states(model, list(map(make_str_input, x_values_train)))\n",
    "valid_hidden_states = get_hidden_states(model, list(map(make_str_input, x_values_valid)))\n",
    "test_hidden_states = get_hidden_states(model, list(map(make_str_input, x_values_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6288a397",
   "metadata": {},
   "source": [
    "### Probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff73d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_embs = sinusoidal_encode(\n",
    "    torch.arange(1000),\n",
    "    min_value=0,\n",
    "    max_value=1000,\n",
    "    embedding_dim=train_hidden_states[0].shape[-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184992d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierProbe(torch.nn.Module):\n",
    "    def __init__(self, emb_dim: int, hidden_dim: int, basis: torch.Tensor, heldout_mask: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.emb_to_latent = torch.nn.Linear(emb_dim, hidden_dim, bias=True)\n",
    "        self.basis_to_latent = torch.nn.Linear(basis.shape[-1], hidden_dim, bias=True)\n",
    "        self.basis: torch.nn.Buffer\n",
    "        self.heldout_mask: torch.nn.Buffer\n",
    "        self.register_buffer(\"basis\", basis)\n",
    "        self.register_buffer(\"heldout_mask\", heldout_mask)\n",
    "    def forward(self, x: Tensor, holdout_eval_tokens: bool) -> Tensor:\n",
    "        latent_x = self.emb_to_latent(x)\n",
    "        # during training, model learns to choose among only training tokens\n",
    "        # but during eval, model must choose among all tokens\n",
    "        # this means that the model is never exposed to the eval tokens during training\n",
    "        latent_choices = self.basis_to_latent(self.basis)\n",
    "        logits = latent_x @ latent_choices.T\n",
    "        if holdout_eval_tokens:\n",
    "            logits[:, self.heldout_mask] = float(\"-inf\")\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed50b402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0     train loss: 11.41 train acc: 0.00  val loss: 6.88 valid acc: 0.00\n",
      "i=500   train loss: 2.04 train acc: 0.84  val loss: 1.28 valid acc: 0.77\n",
      "i=1000  train loss: 1.62 train acc: 0.88  val loss: 1.09 valid acc: 0.70\n",
      "i=1500  train loss: 1.46 train acc: 0.92  val loss: 0.94 valid acc: 0.80\n",
      "i=2000  train loss: 1.39 train acc: 0.92  val loss: 0.98 valid acc: 0.73\n",
      "i=2500  train loss: 1.30 train acc: 0.96  val loss: 0.96 valid acc: 0.79\n",
      "i=3000  train loss: 1.27 train acc: 0.95  val loss: 0.95 valid acc: 0.78\n",
      "i=3500  train loss: 1.25 train acc: 0.94  val loss: 0.81 valid acc: 0.80\n",
      "i=4000  train loss: 1.20 train acc: 0.93  val loss: 0.83 valid acc: 0.80\n",
      "i=4500  train loss: 1.25 train acc: 0.89  val loss: 0.89 valid acc: 0.81\n",
      "i=5000  train loss: 1.18 train acc: 0.94  val loss: 0.78 valid acc: 0.79\n",
      "i=5500  train loss: 1.14 train acc: 0.93  val loss: 0.77 valid acc: 0.81\n",
      "i=6000  train loss: 1.09 train acc: 0.96  val loss: 0.81 valid acc: 0.80\n",
      "i=6500  train loss: 1.13 train acc: 0.93  val loss: 0.89 valid acc: 0.78\n",
      "i=7000  train loss: 1.14 train acc: 0.92  val loss: 0.75 valid acc: 0.79\n",
      "i=7500  train loss: 1.07 train acc: 0.95  val loss: 0.85 valid acc: 0.80\n",
      "i=8000  train loss: 1.04 train acc: 0.96  val loss: 0.82 valid acc: 0.79\n",
      "i=8500  train loss: 1.13 train acc: 0.93  val loss: 0.77 valid acc: 0.80\n",
      "i=9000  train loss: 1.04 train acc: 0.97  val loss: 0.90 valid acc: 0.78\n",
      "i=9500  train loss: 1.05 train acc: 0.96  val loss: 0.84 valid acc: 0.80\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "probe = ClassifierProbe(\n",
    "    emb_dim=train_hidden_states[0].shape[-1],\n",
    "    hidden_dim=100,\n",
    "    basis=basis_embs,\n",
    "    heldout_mask=test_mask,\n",
    ").to(device)\n",
    "\n",
    "layer_idx = 5 # choose the layer to probe\n",
    "optimizer = torch.optim.Adam(probe.parameters(), lr=1e-3)\n",
    "train_labels = torch.tensor([x[0] for x in x_values_train]) # we want to decode the first number token from hidden representation of the last token\n",
    "rng = torch.Generator().manual_seed(0)\n",
    "for i in range(10000):\n",
    "    probe.train()\n",
    "    optimizer.zero_grad()\n",
    "    minibatch_idcs = torch.randint(len(train_labels), size=(256,), generator=rng)\n",
    "    x = train_hidden_states[layer_idx][minibatch_idcs].to(device)\n",
    "    y = train_labels[minibatch_idcs].to(device)\n",
    "    logits = probe(x, holdout_eval_tokens=True)\n",
    "    # add l1 regularization of all params to the loss\n",
    "    loss = torch.nn.functional.cross_entropy(logits, y) + 0.001 * sum(p.abs().sum() for p in probe.parameters())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 500 == 0:\n",
    "        train_acc = (logits.argmax(dim=-1) == y).float().mean()\n",
    "        probe.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_logits = probe(valid_hidden_states[layer_idx].to(device), holdout_eval_tokens=False)\n",
    "            valid_labels = torch.tensor([x[0] for x in x_values_valid]).to(device)\n",
    "            valid_loss = torch.nn.functional.cross_entropy(valid_logits, valid_labels)\n",
    "            accuracy = (valid_logits.argmax(dim=-1) == valid_labels).float().mean()\n",
    "        print(f\"{i=:<5} train loss: {loss.item():.2f} train acc: {train_acc.item():.2f}  val loss: {valid_loss.item():.2f} valid acc: {accuracy.item():.2f}\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
